# Importing the Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics
gold_data= pd.DataFrame()
gold_data
# loading the csv data to a Pandas DataFrame
gold_data = pd.read_csv('gold_price.csv')
gold_data
# print first 5 rows in the dataframe
gold_data.head()
# print last 5 rows of the dataframe
gold_data.tail()
 # number of rows and columns
gold_data.shape
# getting some basic informations about the data
gold_data.info()
 # getting the statistical measures of the data
gold_data.describe()
print(gold_data.columns)
gold_data.drop('Date',axis=1,inplace=True)
correlation =gold_data.corr()
correlation
 # constructing a heatmap to understand the correlatiom
plt.figure(figsize = (8,8))
sns.heatmap(correlation, cbar=True, square=True, fmt='.1f',annot=True,annot_kws={'size':8}, cmap='Greens')
# correlation values of GLD
print(correlation['GLD'])
sns.distplot(gold_data['GLD'],color='Blue')# checking distribution
# spilting the  Features and Target
X = gold_data.drop(['GLD'],axis=1)
Y = gold_data['GLD']
print(X)
print(Y)
# step5 Splitting into Training data and Test Data
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3,random_state=42)
X_train
Y_train
Y_train.shape
X_test
Y_test
# traing the randomforest regressor
from sklearn.ensemble import RandomForestClassifier
regressor = RandomForestRegressor(n_estimators=100)
regressor
# training the model
regressor.fit(X_train,Y_train)  #for training use fit()
# prediction on Test Data
test_data_prediction = regressor.predict(X_test) # for testing use prediction
test_data_prediction
regressor.score(X_train,Y_train)
# R squared error
error_score = metrics.r2_score(Y_test, test_data_prediction)
print("R squared error : ", error_score)  # it is a predefined function by using we got prediction values
# train the model using linaer reggersion
from sklearn.linear_model import LinearRegression
clf=LinearRegression()
clf
clf.fit(X_train,Y_train)
# prediction on Test Data
clf_test_prediction = clf.predict(X_test) # for testing use prediction
clf_test_prediction
clf.score(X_train,Y_train)
# R squared error
error_score = metrics.r2_score(Y_test, clf_test_prediction)
print("R squared error : ", error_score)
# Compare the Actual Values and Predicted Values in a Plot
plt.plot(Y_test, color='blue', label = 'Actual Value')
plt.plot(clf_test_prediction, color='green', label='Predicted Value')
plt.title('Actual Price vs Predicted Price')
plt.xlabel('Number of values')
plt.ylabel('GLD Price')
plt.legend()
plt.show()
import pickle
# save the model
with open ('regressor.pkl','wb')as f :
   pickle.dump(regressor, f)
#save scaler
with open ('clf.pkl','wb')as f :
   pickle.dump(clf, f)
